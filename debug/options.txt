Namespace(config='runs/nmr/srt/config.yaml', curriculum='CelebA', eval_freq=5000, evalnow=False, exit_after=None, full_scale=False, load_dir='', max_eval=None, model_save_interval=5000, n_epochs=3000, output_dir='debug', port='12355', print_model=False, rtpt=None, sample_interval=200, set_step=None, test=False, visnow=False, wandb=False)

SRT(
  (encoder): SRTEncoder(
    (ray_encoder): RayEncoder(
      (pos_encoding): PositionalEncoding()
      (ray_encoding): PositionalEncoding()
    )
    (conv_blocks): Sequential(
      (0): SRTConvBlock(
        (layers): Sequential(
          (0): Conv2d(183, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (3): ReLU()
        )
      )
      (1): SRTConvBlock(
        (layers): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (3): ReLU()
        )
      )
      (2): SRTConvBlock(
        (layers): Sequential(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (3): ReLU()
        )
      )
      (3): SRTConvBlock(
        (layers): Sequential(
          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(768, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (3): ReLU()
        )
      )
    )
    (per_patch_linear): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))
    (transformer): Transformer(
      (layers): ModuleList(
        (0): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (1): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (2): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (3): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (4): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (5): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (6): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (7): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (8): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (9): ModuleList(
          (0): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (attend): Softmax(dim=-1)
              (to_qkv): Linear(in_features=768, out_features=2304, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=768, out_features=768, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (1): PreNorm(
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fn): FeedForward(
              (net): Sequential(
                (0): Linear(in_features=768, out_features=1536, bias=True)
                (1): GELU(approximate='none')
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=1536, out_features=768, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
    )
  )
  (decoder): SRTDecoder(
    (ray_predictor): RayPredictor(
      (query_encoder): RayEncoder(
        (pos_encoding): PositionalEncoding()
        (ray_encoding): PositionalEncoding()
      )
      (transformer): Transformer(
        (layers): ModuleList(
          (0): ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_q): Linear(in_features=180, out_features=768, bias=False)
                (to_kv): Linear(in_features=768, out_features=1536, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=180, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=180, out_features=1536, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=1536, out_features=180, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
          (1): ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_q): Linear(in_features=180, out_features=768, bias=False)
                (to_kv): Linear(in_features=768, out_features=1536, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=768, out_features=180, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=180, out_features=1536, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                  (3): Linear(in_features=1536, out_features=180, bias=True)
                  (4): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
      )
      (output_mlp): Sequential(
        (0): Linear(in_features=180, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=3, bias=True)
      )
    )
  )
)

CCSEncoderDiscriminator(
  (layers): ModuleList(
    (0): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(66, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))
    )
    (1): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(66, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(130, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
    )
    (2): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(130, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(258, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
    )
    (3): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(258, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(256, 400, kernel_size=(1, 1), stride=(2, 2))
    )
    (4): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(400, 400, kernel_size=(1, 1), stride=(2, 2))
    )
    (5): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(400, 400, kernel_size=(1, 1), stride=(2, 2))
    )
    (6): ResidualCCBlock(
      (network): Sequential(
        (0): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): CoordConv(
          (addcoords): AddCoords()
          (conv): Conv2d(402, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
      (proj): Conv2d(400, 400, kernel_size=(1, 1), stride=(2, 2))
    )
  )
  (fromRGB): ModuleList(
    (0): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (3): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (4): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 400, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (5): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 400, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (6): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 400, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (7): AdapterBlock(
      (model): Sequential(
        (0): Conv2d(3, 400, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
  (final_layer): Conv2d(400, 259, kernel_size=(2, 2), stride=(1, 1))
)

{0: {'batch_size': 4, 'num_steps': 12, 'img_size': 64, 'batch_split': 2, 'gen_lr': 6e-05, 'disc_lr': 0.0002}, 200000: {}, 'dataset_path': '/home/ericryanchan/data/celeba/img_align_celeba/*.jpg', 'fov': 12, 'ray_start': 0.88, 'ray_end': 1.12, 'fade_steps': 10000, 'h_stddev': 0.3, 'v_stddev': 0.155, 'h_mean': 1.5707963267948966, 'v_mean': 1.5707963267948966, 'sample_dist': 'gaussian', 'topk_interval': 2000, 'topk_v': 0.6, 'betas': (0, 0.9), 'unique_lr': False, 'weight_decay': 0, 'r1_lambda': 0.2, 'latent_dim': 256, 'grad_clip': 10, 'model': 'SPATIALSIRENBASELINE', 'generator': 'ImplicitGenerator3d', 'discriminator': 'CCSEncoderDiscriminator', 'dataset': 'CelebA', 'clamp_mode': 'relu', 'z_dist': 'gaussian', 'hierarchical_sample': True, 'z_lambda': 0, 'pos_lambda': 15, 'last_back': False, 'eval_last_back': True}